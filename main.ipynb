{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowdsourced mapping dataset from UCI-ML repo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[This dataset]('https://archive.ics.uci.edu/ml/datasets/Crowdsourced+Mapping') was derived from geospatial data from two sources: \n",
    "1. Landsat time-series satellite imagery from the years 2014-2015\n",
    "2. crowdsourced georeferenced polygons with land cover labels obtained from OpenStreetMap. \n",
    "\n",
    "The crowdsourced polygons cover only a small part of the image area, and are used used to extract training data from the image for classifying the rest of the image. The main challenge with the dataset is that both the imagery and the crowdsourced data contain noise (due to cloud cover in the images and innaccurate labeling/digitizing of polygons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import pycaret\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 13"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **class**: The land cover class (impervious, farm, forest, grass, orchard, water) [note: this is the target variable to classify].\n",
    "2. **max_ndvi**: the maximum NDVI (normalized difference vegetation index) value derived from the time-series of satellite images.\n",
    "3. **20150720_N - 20140101_N** : NDVI values extracted from satellite images acquired between January 2014 and July 2015, in reverse chronological order (dates given in the format yyyymmdd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('testing.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse the columns in `train` and `test` dataset, to shift the target column to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10545, 29) (300, 29)\n",
      "(10845, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20140101_N</th>\n",
       "      <th>20140117_N</th>\n",
       "      <th>20140202_N</th>\n",
       "      <th>20140218_N</th>\n",
       "      <th>20140322_N</th>\n",
       "      <th>20140407_N</th>\n",
       "      <th>20140423_N</th>\n",
       "      <th>20140509_N</th>\n",
       "      <th>20140525_N</th>\n",
       "      <th>20140610_N</th>\n",
       "      <th>...</th>\n",
       "      <th>20150226_N</th>\n",
       "      <th>20150314_N</th>\n",
       "      <th>20150330_N</th>\n",
       "      <th>20150415_N</th>\n",
       "      <th>20150501_N</th>\n",
       "      <th>20150517_N</th>\n",
       "      <th>20150602_N</th>\n",
       "      <th>20150720_N</th>\n",
       "      <th>max_ndvi</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433.906</td>\n",
       "      <td>-1180.190</td>\n",
       "      <td>-2203.02</td>\n",
       "      <td>211.328</td>\n",
       "      <td>452.238</td>\n",
       "      <td>366.608</td>\n",
       "      <td>267.138</td>\n",
       "      <td>-1942.490</td>\n",
       "      <td>-1043.160</td>\n",
       "      <td>-921.193</td>\n",
       "      <td>...</td>\n",
       "      <td>-1628.240</td>\n",
       "      <td>630.087</td>\n",
       "      <td>-1739.990</td>\n",
       "      <td>997.904</td>\n",
       "      <td>-1924.36</td>\n",
       "      <td>-1882.030</td>\n",
       "      <td>658.668</td>\n",
       "      <td>637.5950</td>\n",
       "      <td>997.904</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>524.075</td>\n",
       "      <td>-1360.560</td>\n",
       "      <td>-2250.00</td>\n",
       "      <td>220.878</td>\n",
       "      <td>476.972</td>\n",
       "      <td>364.858</td>\n",
       "      <td>120.059</td>\n",
       "      <td>-625.385</td>\n",
       "      <td>-933.934</td>\n",
       "      <td>-954.719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1670.590</td>\n",
       "      <td>707.626</td>\n",
       "      <td>-692.386</td>\n",
       "      <td>914.198</td>\n",
       "      <td>-1672.32</td>\n",
       "      <td>-1625.790</td>\n",
       "      <td>593.705</td>\n",
       "      <td>634.2400</td>\n",
       "      <td>914.198</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3800.810</td>\n",
       "      <td>150.931</td>\n",
       "      <td>2762.57</td>\n",
       "      <td>293.730</td>\n",
       "      <td>300.560</td>\n",
       "      <td>385.203</td>\n",
       "      <td>1056.600</td>\n",
       "      <td>2208.440</td>\n",
       "      <td>1566.160</td>\n",
       "      <td>1562.210</td>\n",
       "      <td>...</td>\n",
       "      <td>849.599</td>\n",
       "      <td>214.564</td>\n",
       "      <td>1077.840</td>\n",
       "      <td>546.371</td>\n",
       "      <td>1071.21</td>\n",
       "      <td>449.735</td>\n",
       "      <td>1206.880</td>\n",
       "      <td>1671.3400</td>\n",
       "      <td>3800.810</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1343.550</td>\n",
       "      <td>600.359</td>\n",
       "      <td>-2202.12</td>\n",
       "      <td>369.214</td>\n",
       "      <td>291.336</td>\n",
       "      <td>304.621</td>\n",
       "      <td>-1227.800</td>\n",
       "      <td>-1786.950</td>\n",
       "      <td>368.622</td>\n",
       "      <td>-1025.880</td>\n",
       "      <td>...</td>\n",
       "      <td>729.790</td>\n",
       "      <td>-858.390</td>\n",
       "      <td>-1564.630</td>\n",
       "      <td>578.807</td>\n",
       "      <td>-1052.63</td>\n",
       "      <td>210.714</td>\n",
       "      <td>-1599.160</td>\n",
       "      <td>58.0174</td>\n",
       "      <td>952.178</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-826.727</td>\n",
       "      <td>626.379</td>\n",
       "      <td>-2197.36</td>\n",
       "      <td>298.320</td>\n",
       "      <td>282.833</td>\n",
       "      <td>432.150</td>\n",
       "      <td>-924.073</td>\n",
       "      <td>-1189.710</td>\n",
       "      <td>155.624</td>\n",
       "      <td>-1813.950</td>\n",
       "      <td>...</td>\n",
       "      <td>683.254</td>\n",
       "      <td>-802.942</td>\n",
       "      <td>-1413.180</td>\n",
       "      <td>515.805</td>\n",
       "      <td>-1256.93</td>\n",
       "      <td>380.436</td>\n",
       "      <td>-1220.880</td>\n",
       "      <td>72.5180</td>\n",
       "      <td>1232.120</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   20140101_N  20140117_N  20140202_N  20140218_N  20140322_N  20140407_N  \\\n",
       "0     433.906   -1180.190    -2203.02     211.328     452.238     366.608   \n",
       "1     524.075   -1360.560    -2250.00     220.878     476.972     364.858   \n",
       "2    3800.810     150.931     2762.57     293.730     300.560     385.203   \n",
       "3   -1343.550     600.359    -2202.12     369.214     291.336     304.621   \n",
       "4    -826.727     626.379    -2197.36     298.320     282.833     432.150   \n",
       "\n",
       "   20140423_N  20140509_N  20140525_N  20140610_N  ...  20150226_N  \\\n",
       "0     267.138   -1942.490   -1043.160    -921.193  ...   -1628.240   \n",
       "1     120.059    -625.385    -933.934    -954.719  ...   -1670.590   \n",
       "2    1056.600    2208.440    1566.160    1562.210  ...     849.599   \n",
       "3   -1227.800   -1786.950     368.622   -1025.880  ...     729.790   \n",
       "4    -924.073   -1189.710     155.624   -1813.950  ...     683.254   \n",
       "\n",
       "   20150314_N  20150330_N  20150415_N  20150501_N  20150517_N  20150602_N  \\\n",
       "0     630.087   -1739.990     997.904    -1924.36   -1882.030     658.668   \n",
       "1     707.626    -692.386     914.198    -1672.32   -1625.790     593.705   \n",
       "2     214.564    1077.840     546.371     1071.21     449.735    1206.880   \n",
       "3    -858.390   -1564.630     578.807    -1052.63     210.714   -1599.160   \n",
       "4    -802.942   -1413.180     515.805    -1256.93     380.436   -1220.880   \n",
       "\n",
       "   20150720_N  max_ndvi  class  \n",
       "0    637.5950   997.904  water  \n",
       "1    634.2400   914.198  water  \n",
       "2   1671.3400  3800.810  water  \n",
       "3     58.0174   952.178  water  \n",
       "4     72.5180  1232.120  water  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.loc[:, ::-1]\n",
    "test = test.loc[:, ::-1]\n",
    "print(train.shape, test.shape)\n",
    "train = pd.concat([train, test], axis=0)\n",
    "print(train.shape)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10845 entries, 0 to 299\n",
      "Data columns (total 29 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   20140101_N  10845 non-null  float64\n",
      " 1   20140117_N  10845 non-null  float64\n",
      " 2   20140202_N  10845 non-null  float64\n",
      " 3   20140218_N  10845 non-null  float64\n",
      " 4   20140322_N  10845 non-null  float64\n",
      " 5   20140407_N  10845 non-null  float64\n",
      " 6   20140423_N  10845 non-null  float64\n",
      " 7   20140509_N  10845 non-null  float64\n",
      " 8   20140525_N  10845 non-null  float64\n",
      " 9   20140610_N  10845 non-null  float64\n",
      " 10  20140626_N  10845 non-null  float64\n",
      " 11  20140813_N  10845 non-null  float64\n",
      " 12  20140930_N  10845 non-null  float64\n",
      " 13  20141016_N  10845 non-null  float64\n",
      " 14  20141101_N  10845 non-null  float64\n",
      " 15  20141117_N  10845 non-null  float64\n",
      " 16  20150109_N  10845 non-null  float64\n",
      " 17  20150125_N  10845 non-null  float64\n",
      " 18  20150210_N  10845 non-null  float64\n",
      " 19  20150226_N  10845 non-null  float64\n",
      " 20  20150314_N  10845 non-null  float64\n",
      " 21  20150330_N  10845 non-null  float64\n",
      " 22  20150415_N  10845 non-null  float64\n",
      " 23  20150501_N  10845 non-null  float64\n",
      " 24  20150517_N  10845 non-null  float64\n",
      " 25  20150602_N  10845 non-null  float64\n",
      " 26  20150720_N  10845 non-null  float64\n",
      " 27  max_ndvi    10845 non-null  float64\n",
      " 28  class       10845 non-null  object \n",
      "dtypes: float64(28), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20140101_N</th>\n",
       "      <th>20140117_N</th>\n",
       "      <th>20140202_N</th>\n",
       "      <th>20140218_N</th>\n",
       "      <th>20140322_N</th>\n",
       "      <th>20140407_N</th>\n",
       "      <th>20140423_N</th>\n",
       "      <th>20140509_N</th>\n",
       "      <th>20140525_N</th>\n",
       "      <th>20140610_N</th>\n",
       "      <th>...</th>\n",
       "      <th>20150210_N</th>\n",
       "      <th>20150226_N</th>\n",
       "      <th>20150314_N</th>\n",
       "      <th>20150330_N</th>\n",
       "      <th>20150415_N</th>\n",
       "      <th>20150501_N</th>\n",
       "      <th>20150517_N</th>\n",
       "      <th>20150602_N</th>\n",
       "      <th>20150720_N</th>\n",
       "      <th>max_ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "      <td>10845.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2566.613900</td>\n",
       "      <td>2564.274632</td>\n",
       "      <td>6071.186700</td>\n",
       "      <td>2041.965505</td>\n",
       "      <td>2669.581329</td>\n",
       "      <td>2030.725088</td>\n",
       "      <td>3011.825105</td>\n",
       "      <td>3022.588646</td>\n",
       "      <td>3633.226888</td>\n",
       "      <td>4758.548958</td>\n",
       "      <td>...</td>\n",
       "      <td>4224.971202</td>\n",
       "      <td>4871.459511</td>\n",
       "      <td>3337.935688</td>\n",
       "      <td>4883.596688</td>\n",
       "      <td>2862.763558</td>\n",
       "      <td>5046.640099</td>\n",
       "      <td>4337.641928</td>\n",
       "      <td>4766.589523</td>\n",
       "      <td>5694.503074</td>\n",
       "      <td>7254.097497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2433.747341</td>\n",
       "      <td>2345.362697</td>\n",
       "      <td>2023.982802</td>\n",
       "      <td>2200.256861</td>\n",
       "      <td>2398.929476</td>\n",
       "      <td>2013.867923</td>\n",
       "      <td>2187.013375</td>\n",
       "      <td>2068.619041</td>\n",
       "      <td>2303.755746</td>\n",
       "      <td>2757.952570</td>\n",
       "      <td>...</td>\n",
       "      <td>2793.572913</td>\n",
       "      <td>2719.822352</td>\n",
       "      <td>2440.250661</td>\n",
       "      <td>2597.452840</td>\n",
       "      <td>2674.749946</td>\n",
       "      <td>2531.963833</td>\n",
       "      <td>2878.973787</td>\n",
       "      <td>2746.093877</td>\n",
       "      <td>2306.413728</td>\n",
       "      <td>1639.115094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4723.980000</td>\n",
       "      <td>-4550.190000</td>\n",
       "      <td>-6807.550000</td>\n",
       "      <td>-232.292000</td>\n",
       "      <td>-4354.630000</td>\n",
       "      <td>-2853.890000</td>\n",
       "      <td>-4212.560000</td>\n",
       "      <td>-4869.010000</td>\n",
       "      <td>-3257.730000</td>\n",
       "      <td>-3991.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-6000.000000</td>\n",
       "      <td>-5604.450000</td>\n",
       "      <td>-3520.840000</td>\n",
       "      <td>-5992.080000</td>\n",
       "      <td>-3232.180000</td>\n",
       "      <td>-5355.400000</td>\n",
       "      <td>-5774.370000</td>\n",
       "      <td>-3345.120000</td>\n",
       "      <td>-3363.640000</td>\n",
       "      <td>338.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>682.089000</td>\n",
       "      <td>689.898000</td>\n",
       "      <td>5605.260000</td>\n",
       "      <td>493.462000</td>\n",
       "      <td>758.502000</td>\n",
       "      <td>429.634000</td>\n",
       "      <td>1007.320000</td>\n",
       "      <td>1403.430000</td>\n",
       "      <td>1397.790000</td>\n",
       "      <td>1991.110000</td>\n",
       "      <td>...</td>\n",
       "      <td>1381.880000</td>\n",
       "      <td>2298.310000</td>\n",
       "      <td>1016.990000</td>\n",
       "      <td>2442.650000</td>\n",
       "      <td>526.384000</td>\n",
       "      <td>2944.310000</td>\n",
       "      <td>1437.920000</td>\n",
       "      <td>2057.630000</td>\n",
       "      <td>4004.240000</td>\n",
       "      <td>7262.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1460.780000</td>\n",
       "      <td>1506.570000</td>\n",
       "      <td>6853.680000</td>\n",
       "      <td>930.116000</td>\n",
       "      <td>1509.160000</td>\n",
       "      <td>1253.860000</td>\n",
       "      <td>2621.700000</td>\n",
       "      <td>2672.840000</td>\n",
       "      <td>3598.150000</td>\n",
       "      <td>5221.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>4241.970000</td>\n",
       "      <td>5642.170000</td>\n",
       "      <td>2889.600000</td>\n",
       "      <td>5629.480000</td>\n",
       "      <td>1589.470000</td>\n",
       "      <td>5550.980000</td>\n",
       "      <td>4379.600000</td>\n",
       "      <td>5258.050000</td>\n",
       "      <td>6726.560000</td>\n",
       "      <td>7878.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4159.290000</td>\n",
       "      <td>4221.210000</td>\n",
       "      <td>7377.720000</td>\n",
       "      <td>2891.180000</td>\n",
       "      <td>4437.570000</td>\n",
       "      <td>2980.640000</td>\n",
       "      <td>4827.940000</td>\n",
       "      <td>4189.810000</td>\n",
       "      <td>5809.840000</td>\n",
       "      <td>7531.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>7127.670000</td>\n",
       "      <td>7382.790000</td>\n",
       "      <td>5533.490000</td>\n",
       "      <td>7244.090000</td>\n",
       "      <td>5439.440000</td>\n",
       "      <td>7425.560000</td>\n",
       "      <td>7298.430000</td>\n",
       "      <td>7480.000000</td>\n",
       "      <td>7583.520000</td>\n",
       "      <td>8117.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8502.020000</td>\n",
       "      <td>8418.230000</td>\n",
       "      <td>8410.330000</td>\n",
       "      <td>8247.630000</td>\n",
       "      <td>8235.400000</td>\n",
       "      <td>8206.780000</td>\n",
       "      <td>7919.070000</td>\n",
       "      <td>8445.410000</td>\n",
       "      <td>7981.820000</td>\n",
       "      <td>8489.970000</td>\n",
       "      <td>...</td>\n",
       "      <td>8422.060000</td>\n",
       "      <td>8452.380000</td>\n",
       "      <td>8001.700000</td>\n",
       "      <td>8499.330000</td>\n",
       "      <td>8267.120000</td>\n",
       "      <td>8516.100000</td>\n",
       "      <td>8650.500000</td>\n",
       "      <td>8566.420000</td>\n",
       "      <td>8377.720000</td>\n",
       "      <td>8650.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         20140101_N    20140117_N    20140202_N    20140218_N    20140322_N  \\\n",
       "count  10845.000000  10845.000000  10845.000000  10845.000000  10845.000000   \n",
       "mean    2566.613900   2564.274632   6071.186700   2041.965505   2669.581329   \n",
       "std     2433.747341   2345.362697   2023.982802   2200.256861   2398.929476   \n",
       "min    -4723.980000  -4550.190000  -6807.550000   -232.292000  -4354.630000   \n",
       "25%      682.089000    689.898000   5605.260000    493.462000    758.502000   \n",
       "50%     1460.780000   1506.570000   6853.680000    930.116000   1509.160000   \n",
       "75%     4159.290000   4221.210000   7377.720000   2891.180000   4437.570000   \n",
       "max     8502.020000   8418.230000   8410.330000   8247.630000   8235.400000   \n",
       "\n",
       "         20140407_N    20140423_N    20140509_N    20140525_N    20140610_N  \\\n",
       "count  10845.000000  10845.000000  10845.000000  10845.000000  10845.000000   \n",
       "mean    2030.725088   3011.825105   3022.588646   3633.226888   4758.548958   \n",
       "std     2013.867923   2187.013375   2068.619041   2303.755746   2757.952570   \n",
       "min    -2853.890000  -4212.560000  -4869.010000  -3257.730000  -3991.910000   \n",
       "25%      429.634000   1007.320000   1403.430000   1397.790000   1991.110000   \n",
       "50%     1253.860000   2621.700000   2672.840000   3598.150000   5221.170000   \n",
       "75%     2980.640000   4827.940000   4189.810000   5809.840000   7531.100000   \n",
       "max     8206.780000   7919.070000   8445.410000   7981.820000   8489.970000   \n",
       "\n",
       "       ...    20150210_N    20150226_N    20150314_N    20150330_N  \\\n",
       "count  ...  10845.000000  10845.000000  10845.000000  10845.000000   \n",
       "mean   ...   4224.971202   4871.459511   3337.935688   4883.596688   \n",
       "std    ...   2793.572913   2719.822352   2440.250661   2597.452840   \n",
       "min    ...  -6000.000000  -5604.450000  -3520.840000  -5992.080000   \n",
       "25%    ...   1381.880000   2298.310000   1016.990000   2442.650000   \n",
       "50%    ...   4241.970000   5642.170000   2889.600000   5629.480000   \n",
       "75%    ...   7127.670000   7382.790000   5533.490000   7244.090000   \n",
       "max    ...   8422.060000   8452.380000   8001.700000   8499.330000   \n",
       "\n",
       "         20150415_N    20150501_N    20150517_N    20150602_N    20150720_N  \\\n",
       "count  10845.000000  10845.000000  10845.000000  10845.000000  10845.000000   \n",
       "mean    2862.763558   5046.640099   4337.641928   4766.589523   5694.503074   \n",
       "std     2674.749946   2531.963833   2878.973787   2746.093877   2306.413728   \n",
       "min    -3232.180000  -5355.400000  -5774.370000  -3345.120000  -3363.640000   \n",
       "25%      526.384000   2944.310000   1437.920000   2057.630000   4004.240000   \n",
       "50%     1589.470000   5550.980000   4379.600000   5258.050000   6726.560000   \n",
       "75%     5439.440000   7425.560000   7298.430000   7480.000000   7583.520000   \n",
       "max     8267.120000   8516.100000   8650.500000   8566.420000   8377.720000   \n",
       "\n",
       "           max_ndvi  \n",
       "count  10845.000000  \n",
       "mean    7254.097497  \n",
       "std     1639.115094  \n",
       "min      338.410000  \n",
       "25%     7262.770000  \n",
       "50%     7878.820000  \n",
       "75%     8117.400000  \n",
       "max     8650.500000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change col names to `pd.DateTime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2014-01-01</th>\n",
       "      <th>2014-01-17</th>\n",
       "      <th>2014-02-02</th>\n",
       "      <th>2014-02-18</th>\n",
       "      <th>2014-03-22</th>\n",
       "      <th>2014-04-07</th>\n",
       "      <th>2014-04-23</th>\n",
       "      <th>2014-05-09</th>\n",
       "      <th>2014-05-25</th>\n",
       "      <th>2014-06-10</th>\n",
       "      <th>...</th>\n",
       "      <th>2015-02-26</th>\n",
       "      <th>2015-03-14</th>\n",
       "      <th>2015-03-30</th>\n",
       "      <th>2015-04-15</th>\n",
       "      <th>2015-05-01</th>\n",
       "      <th>2015-05-17</th>\n",
       "      <th>2015-06-02</th>\n",
       "      <th>2015-07-20</th>\n",
       "      <th>max_ndvi</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433.906</td>\n",
       "      <td>-1180.190</td>\n",
       "      <td>-2203.02</td>\n",
       "      <td>211.328</td>\n",
       "      <td>452.238</td>\n",
       "      <td>366.608</td>\n",
       "      <td>267.138</td>\n",
       "      <td>-1942.490</td>\n",
       "      <td>-1043.160</td>\n",
       "      <td>-921.193</td>\n",
       "      <td>...</td>\n",
       "      <td>-1628.240</td>\n",
       "      <td>630.087</td>\n",
       "      <td>-1739.990</td>\n",
       "      <td>997.904</td>\n",
       "      <td>-1924.36</td>\n",
       "      <td>-1882.030</td>\n",
       "      <td>658.668</td>\n",
       "      <td>637.5950</td>\n",
       "      <td>997.904</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>524.075</td>\n",
       "      <td>-1360.560</td>\n",
       "      <td>-2250.00</td>\n",
       "      <td>220.878</td>\n",
       "      <td>476.972</td>\n",
       "      <td>364.858</td>\n",
       "      <td>120.059</td>\n",
       "      <td>-625.385</td>\n",
       "      <td>-933.934</td>\n",
       "      <td>-954.719</td>\n",
       "      <td>...</td>\n",
       "      <td>-1670.590</td>\n",
       "      <td>707.626</td>\n",
       "      <td>-692.386</td>\n",
       "      <td>914.198</td>\n",
       "      <td>-1672.32</td>\n",
       "      <td>-1625.790</td>\n",
       "      <td>593.705</td>\n",
       "      <td>634.2400</td>\n",
       "      <td>914.198</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3800.810</td>\n",
       "      <td>150.931</td>\n",
       "      <td>2762.57</td>\n",
       "      <td>293.730</td>\n",
       "      <td>300.560</td>\n",
       "      <td>385.203</td>\n",
       "      <td>1056.600</td>\n",
       "      <td>2208.440</td>\n",
       "      <td>1566.160</td>\n",
       "      <td>1562.210</td>\n",
       "      <td>...</td>\n",
       "      <td>849.599</td>\n",
       "      <td>214.564</td>\n",
       "      <td>1077.840</td>\n",
       "      <td>546.371</td>\n",
       "      <td>1071.21</td>\n",
       "      <td>449.735</td>\n",
       "      <td>1206.880</td>\n",
       "      <td>1671.3400</td>\n",
       "      <td>3800.810</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1343.550</td>\n",
       "      <td>600.359</td>\n",
       "      <td>-2202.12</td>\n",
       "      <td>369.214</td>\n",
       "      <td>291.336</td>\n",
       "      <td>304.621</td>\n",
       "      <td>-1227.800</td>\n",
       "      <td>-1786.950</td>\n",
       "      <td>368.622</td>\n",
       "      <td>-1025.880</td>\n",
       "      <td>...</td>\n",
       "      <td>729.790</td>\n",
       "      <td>-858.390</td>\n",
       "      <td>-1564.630</td>\n",
       "      <td>578.807</td>\n",
       "      <td>-1052.63</td>\n",
       "      <td>210.714</td>\n",
       "      <td>-1599.160</td>\n",
       "      <td>58.0174</td>\n",
       "      <td>952.178</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-826.727</td>\n",
       "      <td>626.379</td>\n",
       "      <td>-2197.36</td>\n",
       "      <td>298.320</td>\n",
       "      <td>282.833</td>\n",
       "      <td>432.150</td>\n",
       "      <td>-924.073</td>\n",
       "      <td>-1189.710</td>\n",
       "      <td>155.624</td>\n",
       "      <td>-1813.950</td>\n",
       "      <td>...</td>\n",
       "      <td>683.254</td>\n",
       "      <td>-802.942</td>\n",
       "      <td>-1413.180</td>\n",
       "      <td>515.805</td>\n",
       "      <td>-1256.93</td>\n",
       "      <td>380.436</td>\n",
       "      <td>-1220.880</td>\n",
       "      <td>72.5180</td>\n",
       "      <td>1232.120</td>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2014-01-01  2014-01-17  2014-02-02  2014-02-18  2014-03-22  2014-04-07  \\\n",
       "0     433.906   -1180.190    -2203.02     211.328     452.238     366.608   \n",
       "1     524.075   -1360.560    -2250.00     220.878     476.972     364.858   \n",
       "2    3800.810     150.931     2762.57     293.730     300.560     385.203   \n",
       "3   -1343.550     600.359    -2202.12     369.214     291.336     304.621   \n",
       "4    -826.727     626.379    -2197.36     298.320     282.833     432.150   \n",
       "\n",
       "   2014-04-23  2014-05-09  2014-05-25  2014-06-10  ...  2015-02-26  \\\n",
       "0     267.138   -1942.490   -1043.160    -921.193  ...   -1628.240   \n",
       "1     120.059    -625.385    -933.934    -954.719  ...   -1670.590   \n",
       "2    1056.600    2208.440    1566.160    1562.210  ...     849.599   \n",
       "3   -1227.800   -1786.950     368.622   -1025.880  ...     729.790   \n",
       "4    -924.073   -1189.710     155.624   -1813.950  ...     683.254   \n",
       "\n",
       "   2015-03-14  2015-03-30  2015-04-15  2015-05-01  2015-05-17  2015-06-02  \\\n",
       "0     630.087   -1739.990     997.904    -1924.36   -1882.030     658.668   \n",
       "1     707.626    -692.386     914.198    -1672.32   -1625.790     593.705   \n",
       "2     214.564    1077.840     546.371     1071.21     449.735    1206.880   \n",
       "3    -858.390   -1564.630     578.807    -1052.63     210.714   -1599.160   \n",
       "4    -802.942   -1413.180     515.805    -1256.93     380.436   -1220.880   \n",
       "\n",
       "   2015-07-20  max_ndvi  class  \n",
       "0    637.5950   997.904  water  \n",
       "1    634.2400   914.198  water  \n",
       "2   1671.3400  3800.810  water  \n",
       "3     58.0174   952.178  water  \n",
       "4     72.5180  1232.120  water  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_cols = list(train.columns)[:-2]\n",
    "original_format = '%Y%m%d_N'\n",
    "datetime_columns = [datetime.datetime.strptime(col, original_format).strftime('%Y-%m-%d') for col in original_cols]\n",
    "\n",
    "train.columns = datetime_columns + ['max_ndvi', 'class']\n",
    "test.columns = datetime_columns + ['max_ndvi', 'class']\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 classes of target variable are are:  ['water' 'forest' 'impervious' 'farm' 'grass' 'orchard']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"6 classes of target variable are are: \", train['class'].unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Countplot of \"class\" variable', fontsize=20)\n",
    "plt.tight_layout()\n",
    "ax = sns.countplot(train['class'])\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()+1), ha='center')\n",
    "# plt.savefig('test_countplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_ndvi</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8205</th>\n",
       "      <td>8173.24</td>\n",
       "      <td>orchard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8490</th>\n",
       "      <td>7929.62</td>\n",
       "      <td>orchard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>7084.41</td>\n",
       "      <td>orchard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>7356.68</td>\n",
       "      <td>orchard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>6982.08</td>\n",
       "      <td>orchard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      max_ndvi    class\n",
       "8205   8173.24  orchard\n",
       "8490   7929.62  orchard\n",
       "9104   7084.41  orchard\n",
       "9105   7356.68  orchard\n",
       "9106   6982.08  orchard"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_ndvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7707.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>608.951844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4013.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7616.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7864.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8041.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8416.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          max_ndvi\n",
       "count   100.000000\n",
       "mean   7707.225200\n",
       "std     608.951844\n",
       "min    4013.330000\n",
       "25%    7616.557500\n",
       "50%    7864.345000\n",
       "75%    8041.917500\n",
       "max    8416.930000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orchard_df = train.loc[train['class'] == 'orchard', ['max_ndvi', 'class']]\n",
    "display(orchard_df.head())\n",
    "display(orchard_df.describe())\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x_toplot = orchard_df['max_ndvi'][::2].index\n",
    "y_toplot = orchard_df['max_ndvi'][::2]\n",
    "ax = sns.barplot(y=y_toplot, x=x_toplot, color=\"#2E8540\")\n",
    "# ax = sns.histplot(y_toplot, kde=True)\n",
    "ax.axhline(y=y_toplot.mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.annotate('Mean: {:.2f}'.format(y_toplot.mean()), xy=(0.5, y_toplot.mean()), xytext=(29, y_toplot.mean()+100), color='red', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.title('Plotting all barplots of max_ndvi for class: orchard in intervals of 2', fontsize=20)\n",
    "plt.xlabel('Index values')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('orchard.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_df = train.loc[train['class'] == 'water', ['max_ndvi', 'class']]\n",
    "display(water_df.head())\n",
    "display(water_df.describe())\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x_toplot = water_df['max_ndvi'][::5].index\n",
    "y_toplot = water_df['max_ndvi'][::5]\n",
    "ax = sns.barplot(y=y_toplot, x=x_toplot, color=\"#2E8540\")\n",
    "# ax = sns.histplot(y_toplot, kde=True)\n",
    "ax.axhline(y=y_toplot.mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.annotate('Mean: {:.2f}'.format(y_toplot.mean()), xy=(0.5, y_toplot.mean()), xytext=(25, y_toplot.mean()+100), color='red', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.title('Plotting all barplots of max_ndvi for class: water in intervals of 5', fontsize=20)\n",
    "plt.xlabel('Index values in intervals of 5')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "# xticks = [0, 204] \n",
    "# ax.set_xticks(xticks);\n",
    "plt.savefig('water.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grass_df = train.loc[train['class'] == 'grass', ['max_ndvi', 'class']]\n",
    "display(grass_df.head())\n",
    "display(grass_df.describe())\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x_toplot = grass_df['max_ndvi'][::10].index\n",
    "y_toplot = grass_df['max_ndvi'][::10]\n",
    "ax = sns.barplot(y=y_toplot, x=x_toplot, color=\"#2E8540\")\n",
    "# ax = sns.histplot(y_toplot, kde=True)\n",
    "ax.axhline(y=y_toplot.mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.annotate('Mean: {:.2f}'.format(y_toplot.mean()), xy=(0.5, y_toplot.mean()), xytext=(7, y_toplot.mean()+100), color='red', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.title('Plotting all barplots of max_ndvi for class: grass in intervals of 10', fontsize=20)\n",
    "plt.xlabel('Index values in intervals of 10')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90);\n",
    "# plt.savefig('grass.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impervious_df = train.loc[train['class'] == 'impervious', ['max_ndvi', 'class']]\n",
    "display(impervious_df.head())\n",
    "display(impervious_df.describe())\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x_toplot = impervious_df['max_ndvi'][::20].index\n",
    "y_toplot = impervious_df['max_ndvi'][::20]\n",
    "ax = sns.barplot(y=y_toplot, x=x_toplot, color=\"#2E8540\")\n",
    "# ax = sns.histplot(y_toplot, kde=True)\n",
    "ax.axhline(y=y_toplot.mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.annotate('Mean: {:.2f}'.format(y_toplot.mean()), xy=(0.5, y_toplot.mean()), xytext=(7, y_toplot.mean()+100), color='red', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.title('Plotting all barplots of max_ndvi for class: impervious in intervals of 20', fontsize=20)\n",
    "plt.xlabel('Index values in intervals of 10')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90);\n",
    "plt.savefig('impervious.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_df = train.loc[train['class'] == 'farm', ['max_ndvi', 'class']]\n",
    "display(farm_df.head())\n",
    "display(farm_df.describe())\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x_toplot = farm_df['max_ndvi'][::30].index\n",
    "y_toplot = farm_df['max_ndvi'][::30]\n",
    "ax = sns.barplot(y=y_toplot, x=x_toplot, color=\"#2E8540\")\n",
    "# ax = sns.histplot(y_toplot, kde=True)\n",
    "ax.axhline(y=y_toplot.mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.annotate('Mean: {:.2f}'.format(y_toplot.mean()), xy=(0.5, y_toplot.mean()), xytext=(7, y_toplot.mean()+100), color='red', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.title('Plotting all barplots of max_ndvi for class: farm in intervals of 30', fontsize=20)\n",
    "plt.xlabel('Index values in intervals of 10')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90);\n",
    "plt.savefig('farm.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_df = train.loc[train['class'] == 'forest', ['max_ndvi', 'class']]\n",
    "display(forest_df.head())\n",
    "display(forest_df.describe())\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "x_toplot = forest_df['max_ndvi'][::200].index\n",
    "y_toplot = forest_df['max_ndvi'][::200]\n",
    "ax = sns.barplot(y=y_toplot, x=x_toplot, color=\"#2E8540\")\n",
    "# ax = sns.histplot(y_toplot, kde=True)\n",
    "ax.axhline(y=y_toplot.mean(), color='red', linestyle='--', label='Mean')\n",
    "ax.annotate('Mean: {:.2f}'.format(y_toplot.mean()), xy=(0.5, y_toplot.mean()), xytext=(7, y_toplot.mean()+100), color='red', fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "plt.title('Plotting all barplots of max_ndvi for class: forest in intervals of 200', fontsize=20)\n",
    "plt.xlabel('Index values in intervals of 10')\n",
    "plt.tight_layout()\n",
    "plt.xticks(rotation=90);\n",
    "plt.savefig('forest.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier detection using boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.xticks(rotation=90)\n",
    "sns.boxplot(data=train);\n",
    "# def count_outliers(row):\n",
    "#     z = np.abs((row - row.mean()) / row.std())\n",
    "#     return len(z[z > 3])\n",
    "\n",
    "# # Apply the function to each row in the dataframe\n",
    "# outliers = train.apply(count_outliers, axis=0)\n",
    "# # outliers\n",
    "# plt.savefig('outliers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of NDVI values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train[\"max_ndvi\"], bins=50, kde=True)\n",
    "plt.title(\"Histogram of NDVI Values\")\n",
    "plt.xlabel(\"NDVI Value\")\n",
    "plt.ylabel(\"Frequency\");\n",
    "# plt.savefig('ndvihist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrices - \n",
    "cor_train=train.corr()\n",
    "cor_test=test.corr()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "ax[0].matshow(cor_train); ax[0].set_title(\"Training corr\")\n",
    "ax[1].matshow(cor_test); ax[1].set_title(\"Testing corr\");\n",
    "# plt.savefig('corry.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(cor_train, square=False, annot=True, fmt=\".1f\", cmap='crest');\n",
    "# plt.savefig('heatmap.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating monthly data into one column, and making a new dataframe from that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the YYYY-MM-DD to MM\n",
    "converted_cols = list(pd.to_datetime(datetime_columns).strftime('%m'))\n",
    "\n",
    "# Now, there are some MM repeated, add _i after them\n",
    "counts = {}\n",
    "for i, col in enumerate(converted_cols):\n",
    "    counts[col] = counts.get(col, 0) + 1\n",
    "    if counts[col] > 1:\n",
    "        converted_cols[i] += f'_{counts[col]}'\n",
    "print(converted_cols)\n",
    "\n",
    "# Make a new dataframe of only months and display it\n",
    "df_month_train = train.copy()\n",
    "df_month_train.columns = converted_cols + ['max_ndvi', 'class']\n",
    "df_month_test = test.copy() ##\n",
    "df_month_test.columns = converted_cols + ['max_ndvi', 'class'] ##\n",
    "display(df_month_train)\n",
    "\n",
    "# Concatenate all cols in one\n",
    "months = ['{:02d}'.format(i) for i in range(1, 13)] # utility list of unique months\n",
    "for month in months:\n",
    "    sum_col_train = df_month_train.filter(regex=f'^{month}').sum(axis=1)\n",
    "    df_month_train[month] = sum_col_train\n",
    "    sum_col_test = df_month_test.filter(regex=f'^{month}').sum(axis=1) ##\n",
    "    df_month_test[month] = sum_col_test ##\n",
    "\n",
    "df_month_train = df_month_train.loc[:, ~df_month_train.columns.str.contains(r'_\\d')]\n",
    "df_month_train = df_month_train.drop('12', axis=1)\n",
    "df_month_test = df_month_test.loc[:, ~df_month_test.columns.str.contains(r'_\\d')]\n",
    "df_month_test = df_month_test.drop('12', axis=1)\n",
    "df_month_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_m = df_month_train.corr()\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(cor_m, square=False, annot=True, fmt=\".1f\", cmap='crest');\n",
    "# plt.savefig('monthly.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = train.drop('class', axis=1)\n",
    "# X_test = test.drop('class', axis=1)\n",
    "# y_train = train['class'].copy()\n",
    "# y_test = test['class'].copy()\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = train.drop('class', axis=1)\n",
    "y = train['class'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=300/len(X))\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_train = LabelEncoder()\n",
    "train['class'] = le_train.fit_transform(train['class'])\n",
    "le_test = LabelEncoder()\n",
    "test['class'] = le_test.fit_transform(test['class'])\n",
    "\n",
    "print(\"Encodings: \", dict(zip(le_train.classes_, range(len(le_train.classes_)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"6 classes of target variable are are: \", y_test.unique())\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Countplot of \"class\" variable', fontsize=20)\n",
    "plt.tight_layout()\n",
    "ax = sns.countplot(y_test)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()+1), ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecting best features\n",
    "# from sklearn.feature_selection import f_classif, SelectKBest\n",
    "# # Select the top 10 features based on ANOVA F-value\n",
    "\n",
    "# selector = SelectKBest(score_func=f_classif, k=10)\n",
    "\n",
    "# # Fit the selector on the training data\n",
    "# selector.fit(X_train, y_train)\n",
    "\n",
    "# # Transform the training and testing data\n",
    "# X_train= selector.transform(X_train)\n",
    "# X_test = selector.transform(X_test)\n",
    "# print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, PowerTransformer, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, RFE, f_classif\n",
    "from sklearn.metrics import classification_report, r2_score, accuracy_score\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(random_state=1)\n",
    ")\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "pipe['randomforestclassifier'].get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do SVM and LogisticRegression perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipe_svc = make_pipeline(\n",
    "    StandardScaler(), \n",
    "    # RFE(SVC(kernel='linear'), n_features_to_select=10, importance_getter='coef_'),\n",
    "    # SelectKBest(f_classif, k=10),\n",
    "    # SelectPercentile(),\n",
    "    # PolynomialFeatures(degree=3),\n",
    "    QuantileTransformer(),\n",
    "    # FunctionTransformer(np.signbit),\n",
    "    # FunctionTransformer(lambda x: np.log(np.abs(x))),\n",
    "    SVC())\n",
    "pipe_svc.fit(X_train, y_train)\n",
    "print(\"######## Classification report for SVC ###################\")\n",
    "print(classification_report(y_test, pipe_svc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe_lr = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "print(\"###### Classification report for LogisticRegression ######\")\n",
    "print(classification_report(y_test, pipe_lr.predict(X_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, SVM was actually even better than RandomForestClassifier!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(pipe_svc, X_test, y_test,cv=10, scoring='accuracy', \n",
    "                        return_train_score=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: red;\"> WARNING! below code takes atleast 2 min to run (when all CPU resources are used\n",
    "using <code>njobs=-1</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for i, estim in enumerate([pipe, pipe_svc, pipe_lr]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    train_sizes, train_scores, test_scores =\\\n",
    "                    learning_curve(estimator=estim,\n",
    "                                X=X_train,\n",
    "                                y=y_train,\n",
    "                                train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                cv=10,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_mean,\n",
    "            color='blue', marker='o',\n",
    "            markersize=5, label='Training accuracy')\n",
    "\n",
    "    plt.fill_between(train_sizes,\n",
    "                    train_mean + train_std,\n",
    "                    train_mean - train_std,\n",
    "                    alpha=0.15, color='blue')\n",
    "\n",
    "    plt.plot(train_sizes, test_mean,\n",
    "            color='green', linestyle='--',\n",
    "            marker='s', markersize=5,\n",
    "            label='Validation accuracy')\n",
    "\n",
    "    plt.fill_between(train_sizes,\n",
    "                    test_mean + test_std,\n",
    "                    test_mean - test_std,\n",
    "                    alpha=0.15, color='green')\n",
    "\n",
    "    # plt.grid()\n",
    "    plt.xlabel('Number of training examples')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Base {estim[1]}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim([0.5, 1.03])\n",
    "    plt.tight_layout()\n",
    "# plt.savefig('aftermodification.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc['svc'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "# for i, param_to_be_tuned in enumerate(random_grid.keys()):\n",
    "#     plt.subplot(2,2,i+1)\n",
    "param_to_be_tuned = 'svc__C'\n",
    "param_range = list(np.arange(1, 4.5, 0.5))\n",
    "train_scores, test_scores = validation_curve(\n",
    "                estimator=pipe_svc, \n",
    "                X=X_train, \n",
    "                y=y_train, \n",
    "                param_name = param_to_be_tuned, \n",
    "                param_range = param_range,\n",
    "                cv=10,\n",
    "                n_jobs=-1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean, \n",
    "        color='blue', marker='o', \n",
    "        markersize=5, label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std,\n",
    "                train_mean - train_std, alpha=0.15,\n",
    "                color='blue')\n",
    "\n",
    "plt.plot(param_range, test_mean, \n",
    "        color='green', linestyle='--', \n",
    "        marker='s', markersize=5, \n",
    "        label='Validation accuracy')\n",
    "\n",
    "plt.fill_between(param_range, \n",
    "                test_mean + test_std,\n",
    "                test_mean - test_std, \n",
    "                alpha=0.15, color='green')\n",
    "\n",
    "# Add numerical values on top of each point\n",
    "for i, value in enumerate(train_mean):\n",
    "    plt.text(param_range[i], value, f'{value:.3f}', ha='center', va='bottom')\n",
    "for i, value in enumerate(test_mean):\n",
    "    plt.text(param_range[i], value, f'{value:.3f}', ha='center', va='top')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(f'{param_to_be_tuned}')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.tight_layout()\n",
    "# plt.savefig('validation_curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "random_grid = {'svc__kernel': ['linear', 'poly', 'rbf'],\n",
    "               'svc__C': list(np.arange(0.5, 5.5, 0.5)),\n",
    "              }\n",
    "# Create the random grid\n",
    "pprint(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "svc_RSCV = RandomizedSearchCV(estimator = pipe_svc, \n",
    "                             param_distributions = random_grid, \n",
    "                             n_iter = 10, cv=10, verbose = 2, \n",
    "                             random_state = 42, n_jobs = -1, scoring='accuracy')\n",
    "svc_RSCV.fit(X_train, y_train)\n",
    "print(f'Best hyperparameters: {svc_RSCV.best_params_}')\n",
    "print(f'Best training accuracy: {svc_RSCV.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# X_test = StandardScaler().fit_transform(X_test)\n",
    "\n",
    "print(\"Actual accuracy on test set->\")\n",
    "base_acc = accuracy_score(y_test, pipe.predict(X_test))\n",
    "print(\"Base model: \", base_acc)\n",
    "rscv_acc = accuracy_score(y_test, svc_RSCV.best_estimator_.predict(X_test))\n",
    "print(\"RSCV model: \", rscv_acc)\n",
    "print('Improvement of {:0.2f}%.'.format(100 * (rscv_acc - base_acc) / base_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Normalized confusion matrix\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "disp = ConfusionMatrixDisplay.from_estimator(pipe_svc, X_test, y_test, ax=plt.gca(),\n",
    "                                             display_labels = list(le_train.classes_),\n",
    "                                             xticks_rotation='vertical',values_format='.2f', \n",
    "                                             normalize = 'true'\n",
    "                                             )\n",
    "# pprint(disp.confusion_matrix)\n",
    "# plt.savefig('confusion_matrix_all_classes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, pipe_svc.predict(X_test))\n",
    "\n",
    "# Loop through each class and compute the relevant metrics\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plt.tight_layout()\n",
    "for i, name in enumerate(list(le_train.classes_)):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.title(f'Class: {name}')\n",
    "    tp = cm[i,i]                 # True positives\n",
    "    fp = cm[:,i].sum() - tp      # False positives\n",
    "    fn = cm[i,:].sum() - tp      # False negatives\n",
    "    tn = cm.sum() - tp - fp - fn # True negatives\n",
    "    # Plot the heatmap\n",
    "    sns.heatmap([[tp, fp],[fn, tn]], annot=True, fmt='.0f',cmap='viridis', cbar=False, \n",
    "                  xticklabels=['True', 'False'], yticklabels=['True', 'False'], ax=plt.gca())\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('Actual labels')\n",
    "    plt.tight_layout()\n",
    "# plt.savefig('confusion_matrix_subplotclasses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the monthly dataset\n",
    "# X_month_train = df_month_train.drop('class', axis=1)\n",
    "# y_month_train = df_month_train['class'].copy()\n",
    "# X_month_test = df_month_test.drop('class', axis=1)\n",
    "# y_month_test = df_month_test['class'].copy()\n",
    "# print(X_month_train.shape, X_month_test.shape, y_month_train.shape, y_month_test.shape)\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_month_train, y_month_train)\n",
    "# y_month_pred = model.predict(X_month_test)\n",
    "# print(accuracy_score(y_month_pred, y_month_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.classification import *\n",
    "\n",
    "# clf = setup(data = train, target = 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(best_model, plot='auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = predict_model(best_model, data = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
